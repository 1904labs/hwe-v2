{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c22a525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/11 17:09:31 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"HWE Week 1 App\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722a30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel('WARN')\n",
    "df = spark.read.text('../alice-in-wonderland.txt')\n",
    "df.createOrReplaceTempView('book')\n",
    "query = open('./sparkhelloworld/query.sql').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6a2b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with words as (\n",
      "    select explode(split(lcase(regexp_replace(value, '[^a-zA-Z ]', '')), ' ')) as word \n",
      "    from book\n",
      ")\n",
      "select word, count(*) as ct\n",
      "from words\n",
      "where len(word) > 0\n",
      "group by word\n",
      "order by ct desc\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced652f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|    alices|\n",
      "|adventures|\n",
      "|        in|\n",
      "|wonderland|\n",
      "|          |\n",
      "|        by|\n",
      "|     lewis|\n",
      "|   carroll|\n",
      "|          |\n",
      "|       the|\n",
      "|millennium|\n",
      "|   fulcrum|\n",
      "|   edition|\n",
      "|          |\n",
      "|          |\n",
      "|  contents|\n",
      "|          |\n",
      "|          |\n",
      "|   chapter|\n",
      "|         i|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "words = df.select(explode(split(lower(regexp_replace(\"value\", '[^a-zA-Z ]', '')), ' ')).alias('word'))\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7054a754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|  the| 1815|\n",
      "|  and|  911|\n",
      "|   to|  802|\n",
      "|    a|  690|\n",
      "|   of|  626|\n",
      "|   it|  538|\n",
      "|  she|  538|\n",
      "| said|  462|\n",
      "|  you|  430|\n",
      "|   in|  427|\n",
      "|    i|  401|\n",
      "|alice|  385|\n",
      "|  was|  359|\n",
      "| that|  291|\n",
      "|   as|  272|\n",
      "|  her|  248|\n",
      "| with|  226|\n",
      "|   at|  220|\n",
      "|   on|  204|\n",
      "|  all|  197|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = words.where(length(\"word\") > 0).groupBy(\"word\").count().orderBy(desc(\"count\"))\n",
    "counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694447a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
